{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import bpy\n",
    "import time\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hand project starts running!\n"
     ]
    }
   ],
   "source": [
    "print(\"The hand project starts running!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get parameters from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key='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')\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}],\n",
    "    stream=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "Opening_Voice='You can describe a scene to me, and I will respond to that with gesture.'\n",
    "Opening_Voice_tts=gTTS(text=Opening_Voice,lang='en')\n",
    "Opening_Voice_tts.save('opening_voice.mp3')\n",
    "os.system(\"afplay opening_voice.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start recording "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import wave\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import time\n",
    "import threading\n",
    "\n",
    "recording = None\n",
    "\n",
    "# recording function\n",
    "def record_audio(sample_rate, channels):\n",
    "    global recording\n",
    "    print(\"start recording...\")\n",
    "    recording = sd.rec(frames=10*sample_rate,samplerate=sample_rate, channels=channels, dtype='int16')\n",
    "    print(\"recording ended, saving the file....\")\n",
    "\n",
    "def stop_recording(filename,sample_rate,channels,recording):\n",
    "    print('recording has been stopped')\n",
    "    sd.stop()\n",
    "    sf.write(filename, recording, sample_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7121fb22450c413dab190e61d328c596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Start', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8734f0b42cc4b3d8f2b8f3ca015575f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Stop', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_button = widgets.Button(description=\"Start\")\n",
    "stop_button = widgets.Button(description=\"Stop\")\n",
    "\n",
    "# parameter\n",
    "duration = 30  \n",
    "sample_rate = 44100  \n",
    "channels = 1 \n",
    "\n",
    "start_button.on_click(lambda x: record_audio(sample_rate, channels))\n",
    "stop_button.on_click(lambda x: stop_recording('record.wav',sample_rate,channels=1,recording=recording))\n",
    "\n",
    "display(start_button, stop_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use LLM to process the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scene' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      2\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      3\u001b[0m         {\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m Imagine you are a hand with your own emotions, and you have six fingers.\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m             \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNow, I am describing a scene to you. Please give me feedback based on this scene: \u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;124m             \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mscene\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m             Please give me feedback in gesture. The gesture should have 3 parameters:\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m             1. scope of left and right, it should be a float in range [-100,100], far left is -100, far right end is 100;\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m             2. scope of up and down, it should be a float in range[-100,10], up limit is 10, down limit is -100; \u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m             3. scope of bending the fingers, it should be a float in range [0,100], bending max is 100, stretching max is 0;\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m             Then, put them in an array in order of [1,2,3]\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m             Give me 10 arrays in a sequence, then tell me why you do that. Use the pattern Explanation: your explanation when you start to explain.\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m              \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m         }\n\u001b[1;32m     18\u001b[0m     ],\n\u001b[1;32m     19\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scene' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\":\n",
    "            f\"\"\" Imagine you are a hand with your own emotions, and you have six fingers.\n",
    "             \"Now, I am describing a scene to you. Please give me feedback based on this scene: \n",
    "             {scene}\n",
    "             Please give me feedback in gesture. The gesture should have 3 parameters:\n",
    "             1. scope of left and right, it should be a float in range [-100,100], far left is -100, far right end is 100;\n",
    "             2. scope of up and down, it should be a float in range[-100,10], up limit is 10, down limit is -100; \n",
    "             3. scope of bending the fingers, it should be a float in range [0,100], bending max is 100, stretching max is 0;\n",
    "             Then, put them in an array in order of [1,2,3]\n",
    "             Give me 10 arrays in a sequence, then tell me why you do that. Use the pattern Explanation: your explanation when you start to explain.\n",
    "              \"\"\",\n",
    "\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response_string=response.choices[0].message.content\n",
    "print(response_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and transfer parameter into blender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing file route and scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read blend: \"/Users/hexuchen/Desktop/the_hand/the_hand_mockup_nov01.blend\"\n",
      "Object: hand_armature, Parent: None\n",
      "Object: Camera, Parent: None\n",
      "Object: Middle01, Parent: hand_armature\n",
      "Object: Middle02, Parent: hand_armature\n",
      "Object: Middle03, Parent: hand_armature\n",
      "Object: Middle04, Parent: hand_armature\n",
      "Object: Ring01, Parent: hand_armature\n",
      "Object: Ring02, Parent: hand_armature\n",
      "Object: Ring03, Parent: hand_armature\n",
      "Object: Ring04, Parent: hand_armature\n",
      "Object: Pink01, Parent: hand_armature\n",
      "Object: Pink02, Parent: hand_armature\n",
      "Object: Pink03, Parent: hand_armature\n",
      "Object: Pink04, Parent: hand_armature\n",
      "Object: Index02, Parent: hand_armature\n",
      "Object: Index03, Parent: hand_armature\n",
      "Object: Index04, Parent: hand_armature\n",
      "Object: Index01, Parent: hand_armature\n",
      "Object: Thumb01, Parent: hand_armature\n",
      "Object: Thumb02, Parent: hand_armature\n",
      "Object: Thumb03, Parent: hand_armature\n",
      "Bone Name: root\n",
      "Bone Name: Middle01\n",
      "Bone Name: Middle02\n",
      "Bone Name: Middle03\n",
      "Bone Name: Middle04\n",
      "Bone Name: Ring01\n",
      "Bone Name: Ring02\n",
      "Bone Name: Ring03\n",
      "Bone Name: Ring04\n",
      "Bone Name: Index01\n",
      "Bone Name: Index02\n",
      "Bone Name: Index03\n",
      "Bone Name: Index04\n",
      "Bone Name: Pink01\n",
      "Bone Name: Pink02\n",
      "Bone Name: Pink03\n",
      "Bone Name: Pink04\n",
      "Bone Name: Thumb01\n",
      "Bone Name: Thumb02\n",
      "Bone Name: Thumb03\n"
     ]
    }
   ],
   "source": [
    "bpy.ops.wm.open_mainfile(filepath='/Users/hexuchen/Desktop/the_hand/the_hand_mockup_nov01.blend')\n",
    "#bpy.ops.mesh.primitive_uv_sphere_add(radius=2)\n",
    "\n",
    "for obj in bpy.context.scene.objects:\n",
    "    if obj.parent:\n",
    "        print(f\"Object: {obj.name}, Parent: {obj.parent.name}\")\n",
    "    else:\n",
    "        print(f\"Object: {obj.name}, Parent: None\")\n",
    "\n",
    "armature_obj = bpy.data.objects['hand_armature']  \n",
    "\n",
    "for bone in armature_obj.data.bones:\n",
    "    print(f\"Bone Name: {bone.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[finger(stretch=[-0.07819074915555556, 0.32114057688888886], up_down=[0.0, 0.0], bend=[0.0, 0.0]), finger(stretch=[6.230825323333334, 6.440264829999999], up_down=[0.0, 0.0], bend=[0.0, 0.0]), finger(stretch=[0.0, 0.0], up_down=[0.0, 0.0], bend=[0.0, 0.0]), finger(stretch=[0.013456488303333333, 0.11344639944444444], up_down=[0.0, 0.0], bend=[0.0, 0.0]), finger(stretch=[0.0, 0.20071286055555554], up_down=[0.0, 0.0], bend=[0.0, 0.0])]\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "pi = 3.1415926\n",
    "@dataclass\n",
    "class finger:\n",
    "    stretch:range #rotation of finger root\n",
    "    up_down:range #rotation of finger root\n",
    "    bend:range #add up of rotation of finger tips\n",
    "\n",
    "thumb= finger(stretch=[-4.48/180*pi,18.4/180*pi],up_down=[0/180*pi,0/180*pi],bend=[0/180*pi,0/180*pi])\n",
    "index= finger(stretch=[357/180*pi,369/180*pi],up_down=[0/180*pi,0/180*pi],bend=[0/180*pi,0/180*pi])\n",
    "middle= finger(stretch=[0/180*pi,0/180*pi],up_down=[0/180*pi,0/180*pi],bend=[0/180*pi,0/180*pi])\n",
    "ring= finger(stretch=[0.771/180*pi,6.5/180*pi],up_down=[0/180*pi,0/180*pi],bend=[0/180*pi,0/180*pi])\n",
    "pink= finger(stretch=[0/180*pi,11.5/180*pi],up_down=[0/180*pi,0/180*pi],bend=[0/180*pi,0/180*pi])\n",
    "\n",
    "fingers=[thumb,index,middle,ring,pink]\n",
    "print(fingers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.07819074915555556, 0.0, 0.0], [6.251769274, 0.0, 0.0], [0.0, 0.0, 0.0], [0.03345447053155556, 0.0, 0.0], [0.20071286055555554, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "stretch=0 # from 0 to 1\n",
    "up_down=0 # from 0 to 1\n",
    "bend=0 # from 0 to 1\n",
    "\n",
    "\n",
    "thumb_data=[stretch,bend,up_down]\n",
    "\n",
    "test_frame=[\n",
    "    #thumb,index,middle,ring,pink\n",
    "    # stretch,up_down,bend\n",
    "   [0,0,0],[0.1,0.1,0.1],[0.5,0.5,0.5],[0.2,0.2,0.2],[1,1,1]\n",
    "]\n",
    "\n",
    "remapped_output=[]\n",
    "for i in range(0,5):\n",
    "    remapped_stretch=(fingers[i].stretch[1]-fingers[i].stretch[0])*test_frame[i][0]+fingers[i].stretch[0]\n",
    "    remapped_up_down=(fingers[i].up_down[1]-fingers[i].up_down[0])*test_frame[i][1]+fingers[i].up_down[0]\n",
    "    remapped_bend=(fingers[i].bend[1]-fingers[i].bend[0])*test_frame[i][2]+fingers[i].bend[0]\n",
    "    remapped_output.append([remapped_stretch,remapped_up_down,remapped_bend])\n",
    "    \n",
    "print(remapped_output)\n",
    "\n",
    "#parameters used in video\n",
    "left_right_speed=0\n",
    "up_down_speed=0\n",
    "bend_speed=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current frame : 1\n",
      "last rotation angle for Thumb01 is: 0.3218446671962738\n",
      "new rotation angle for Thumb01 is: -0.07819074915555556\n",
      "last rotation angle for Index01 is: 6.439478397369385\n",
      "new rotation angle for Index01 is: 6.251769274\n",
      "last rotation angle for Middle01 is: 0.0\n",
      "new rotation angle for Middle01 is: 0.0\n",
      "last rotation angle for Ring01 is: 0.11346472799777985\n",
      "new rotation angle for Ring01 is: 0.03345447053155556\n",
      "last rotation angle for Pink01 is: 0.19999998807907104\n",
      "new rotation angle for Pink01 is: 0.20071286055555554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'FINISHED'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the pose frame\n",
    "bpy.context.scene.frame_set(1)\n",
    "\n",
    "print(\"current frame :\", bpy.context.scene.frame_current)\n",
    "\n",
    "bpy.context.view_layer.objects.active = armature_obj #Go into armature's pose mode\n",
    "bpy.ops.object.mode_set(mode='POSE')\n",
    "\n",
    "bone_name= ['Thumb01','Index01','Middle01','Ring01','Pink01']\n",
    "\n",
    "# stretch\n",
    "for i in range(0,5):\n",
    "    bone=armature_obj.pose.bones[bone_name[i]]\n",
    "    print(f'last rotation angle for {bone_name[i]} is: {bone.rotation_axis_angle[0]}')\n",
    "    bone.rotation_axis_angle[0]=remapped_output[i][0]\n",
    "    print(f'new rotation angle for {bone_name[i]} is: {remapped_output[i][0]}')\n",
    "bone.keyframe_insert(data_path=\"location\", frame=bpy.context.scene.frame_current)\n",
    "\n",
    "\n",
    "bpy.context.view_layer.update()\n",
    "\n",
    "#save the adjustment and go back to object mode\n",
    "bpy.ops.object.mode_set(mode='OBJECT')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the resolution and sample time\n",
    "\n",
    "bpy.context.scene.render.engine = 'CYCLES'\n",
    "bpy.context.scene.render.resolution_x = 1920\n",
    "bpy.context.scene.render.resolution_y = 1080\n",
    "bpy.context.scene.cycles.samples=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time now is: 17:16:07 24_11_01\n",
      "Fra:1 Mem:12.56M (Peak 12.56M) | Time:00:00.02 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Synchronizing object | Middle01\n",
      "Fra:1 Mem:12.56M (Peak 12.56M) | Time:00:00.02 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Synchronizing object | Middle02\n",
      "Fra:1 Mem:12.56M (Peak 12.56M) | Time:00:00.02 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Synchronizing object | Ring01\n",
      "Fra:1 Mem:12.56M (Peak 12.56M) | Time:00:00.02 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Synchronizing object | Ring02\n",
      "Fra:1 Mem:12.56M (Peak 12.56M) | Time:00:00.02 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Synchronizing object | Ring03\n",
      "Fra:1 Mem:12.56M (Peak 12.56M) | Time:00:00.02 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Synchronizing object | Thumb03\n",
      "Fra:1 Mem:12.57M (Peak 12.57M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Synchronizing object | Ring04\n",
      "Fra:1 Mem:12.57M (Peak 12.57M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Synchronizing object | Thumb02\n",
      "Fra:1 Mem:12.57M (Peak 12.57M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Synchronizing object | Pink02\n",
      "Fra:1 Mem:12.57M (Peak 12.57M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Synchronizing object | Pink03\n",
      "Fra:1 Mem:12.58M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Synchronizing object | Thumb01\n",
      "Fra:1 Mem:12.58M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Synchronizing object | Pink04\n",
      "Fra:1 Mem:12.58M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Synchronizing object | Index01\n",
      "Fra:1 Mem:12.58M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Synchronizing object | Index04\n",
      "Fra:1 Mem:12.58M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Synchronizing object | Index03\n",
      "Fra:1 Mem:12.58M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Synchronizing object | Index02\n",
      "Fra:1 Mem:12.58M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Initializing\n",
      "Fra:1 Mem:11.68M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Waiting for render to start\n",
      "Fra:1 Mem:11.68M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Loading render kernels (may take a few minutes the first time)\n",
      "Fra:1 Mem:11.68M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Updating Scene\n",
      "Fra:1 Mem:11.68M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Updating Shaders\n",
      "Fra:1 Mem:11.76M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Updating Procedurals\n",
      "Fra:1 Mem:11.76M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Updating Background\n",
      "Fra:1 Mem:11.76M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Updating Camera\n",
      "Fra:1 Mem:11.76M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Updating Meshes Flags\n",
      "Fra:1 Mem:11.76M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Updating Objects\n",
      "Fra:1 Mem:11.76M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Updating Objects | Copying Transformations to device\n",
      "Fra:1 Mem:11.77M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Updating Objects | Applying Static Transformations\n",
      "Fra:1 Mem:11.77M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Updating Particle Systems\n",
      "Fra:1 Mem:11.77M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Updating Particle Systems | Copying Particles to device\n",
      "Fra:1 Mem:11.77M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Updating Meshes\n",
      "Fra:1 Mem:11.77M (Peak 12.58M) | Time:00:00.03 | Mem:0.00M, Peak:0.00M | Scene, ViewLayer | Updating Mesh | Computing attributes\n",
      "Fra:1 Mem:11.77M (Peak 12.58M) | Time:00:00.03 | Mem:0.01M, Peak:0.01M | Scene, ViewLayer | Updating Mesh | Copying Attributes to device\n",
      "Fra:1 Mem:11.77M (Peak 12.58M) | Time:00:00.03 | Mem:0.01M, Peak:0.01M | Scene, ViewLayer | Updating Scene BVH | Building\n",
      "Fra:1 Mem:11.77M (Peak 12.58M) | Time:00:00.03 | Mem:0.01M, Peak:0.01M | Scene, ViewLayer | Updating Scene BVH | Building BVH\n",
      "Fra:1 Mem:11.77M (Peak 12.58M) | Time:00:00.03 | Mem:0.01M, Peak:0.01M | Scene, ViewLayer | Updating Scene BVH | Building BVH 0%\n",
      "Fra:1 Mem:11.77M (Peak 12.58M) | Time:00:00.03 | Mem:0.03M, Peak:0.03M | Scene, ViewLayer | Updating Scene BVH | Copying BVH to device\n",
      "Fra:1 Mem:11.77M (Peak 12.58M) | Time:00:00.03 | Mem:0.03M, Peak:0.03M | Scene, ViewLayer | Updating Mesh | Computing normals\n",
      "Fra:1 Mem:11.78M (Peak 12.58M) | Time:00:00.03 | Mem:0.03M, Peak:0.03M | Scene, ViewLayer | Updating Mesh | Copying Mesh to device\n",
      "Fra:1 Mem:11.78M (Peak 12.58M) | Time:00:00.03 | Mem:0.04M, Peak:0.04M | Scene, ViewLayer | Updating Objects Flags\n",
      "Fra:1 Mem:11.78M (Peak 12.58M) | Time:00:00.03 | Mem:0.04M, Peak:0.04M | Scene, ViewLayer | Updating Primitive Offsets\n",
      "Fra:1 Mem:11.78M (Peak 12.58M) | Time:00:00.03 | Mem:0.04M, Peak:0.04M | Scene, ViewLayer | Updating Images\n",
      "Fra:1 Mem:11.78M (Peak 12.58M) | Time:00:00.03 | Mem:0.04M, Peak:0.04M | Scene, ViewLayer | Updating Camera Volume\n",
      "Fra:1 Mem:11.78M (Peak 12.58M) | Time:00:00.03 | Mem:0.04M, Peak:0.04M | Scene, ViewLayer | Updating Lookup Tables\n",
      "Fra:1 Mem:11.78M (Peak 12.58M) | Time:00:00.03 | Mem:0.12M, Peak:0.12M | Scene, ViewLayer | Updating Lights\n",
      "Fra:1 Mem:11.78M (Peak 12.58M) | Time:00:00.03 | Mem:0.12M, Peak:0.12M | Scene, ViewLayer | Updating Lights | Computing tree\n",
      "Fra:1 Mem:11.78M (Peak 12.58M) | Time:00:00.03 | Mem:0.12M, Peak:0.12M | Scene, ViewLayer | Updating Integrator\n",
      "Fra:1 Mem:12.78M (Peak 12.78M) | Time:00:00.03 | Mem:1.12M, Peak:1.12M | Scene, ViewLayer | Updating Film\n",
      "Fra:1 Mem:12.78M (Peak 12.78M) | Time:00:00.03 | Mem:1.04M, Peak:1.12M | Scene, ViewLayer | Updating Lookup Tables\n",
      "Fra:1 Mem:12.78M (Peak 12.78M) | Time:00:00.03 | Mem:1.12M, Peak:1.12M | Scene, ViewLayer | Updating Baking\n",
      "Fra:1 Mem:12.78M (Peak 12.78M) | Time:00:00.03 | Mem:1.12M, Peak:1.12M | Scene, ViewLayer | Updating Device | Writing constant memory\n",
      "Fra:1 Mem:12.79M (Peak 12.79M) | Time:00:00.03 | Mem:1.12M, Peak:1.12M | Scene, ViewLayer | Loading denoising kernels (may take a few minutes the first time)\n",
      "Fra:1 Mem:12.79M (Peak 12.79M) | Time:00:00.03 | Mem:1.12M, Peak:1.12M | Scene, ViewLayer | Sample 0/100\n",
      "Fra:1 Mem:163.11M (Peak 163.11M) | Time:00:00.16 | Remaining:00:12.35 | Mem:151.41M, Peak:151.41M | Scene, ViewLayer | Sample 1/100\n",
      "Fra:1 Mem:163.11M (Peak 163.11M) | Time:00:04.57 | Remaining:00:01.13 | Mem:151.41M, Peak:151.41M | Scene, ViewLayer | Sample 80/100\n",
      "Fra:1 Mem:163.11M (Peak 210.57M) | Time:00:07.92 | Remaining:00:00.32 | Mem:151.41M, Peak:151.41M | Scene, ViewLayer | Sample 96/100\n",
      "Fra:1 Mem:226.39M (Peak 321.31M) | Time:00:10.81 | Remaining:00:00.44 | Mem:151.41M, Peak:151.41M | Scene, ViewLayer | Sample 0/100\n",
      "Fra:1 Mem:226.39M (Peak 321.31M) | Time:00:10.81 | Remaining:00:00.44 | Mem:151.41M, Peak:151.41M | Scene, ViewLayer | Finished\n",
      "Saved: '/Users/hexuchen/Desktop/the_hand/output/output_17:16:07 24_11_01.png'\n",
      "Time: 00:10.97 (Saving: 00:00.15)\n",
      "\n",
      "<Vector (0.0000, 0.0000, 0.0000)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "formatted_time = datetime.now().strftime(\"%H:%M:%S %y_%m_%d\")\n",
    "print(\"The time now is: \"+formatted_time)\n",
    "\n",
    "bpy.context.scene.render.filepath = f'/Users/hexuchen/Desktop/the_hand/output/output_{formatted_time}.png'\n",
    "bpy.ops.render.render(write_still=True)\n",
    "print(bone.location)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
